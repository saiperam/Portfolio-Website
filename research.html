<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research</title>
    <link rel="stylesheet" href="src/styles.css">
</head>
<body>
    <header>
        <h1>Research</h1>
        <nav>
            <a href="index.html">Home</a>
            <a href="about.html">About Me</a>
            <a href="projects.html">Projects</a>
            <a href="industry.html">Industry Experience</a>
            <a href="academic.html">Academic Involvement</a>
            <a href="contact.html">Contact</a>
        </nav>
    </header>

    <main>

        <section>
            <h2>Surgical Robotics at The ARTS Lab</h2>
            <p>
                <strong>Surgical Robotics Researcher</strong> 路 
                <em><a href="https://sites.utexas.edu/arts-lab/" target="_blank">The Advanced Robotic Technologies for Surgery (ARTS) Lab</a></em> 路 
                Texas Robotics<br>
            </p>
            <p>
                Conducting research on robotic surgical systems with integration through <strong>ROS2</strong> and <strong>Gazebo</strong>. 
                My focus is on enhancing robotic motion planning, simulation, and control strategies for advancing surgical robotics capabilities.
            </p>
        </section>
        
        <section>
            <h2>Autonomous Vehicle Systems at NOVA</h2>
            <p><strong>AV Perception and Planning Researcher</strong> 路 <em> NOVA: Self-Driving Research Lab</em> 路 UT Dallas<br>
            <p>I am an active member of the NOVA research group, which focuses on advancing autonomous driving technologies. As part of this program, we have developed a fully functional vehicle prototype, equipped with cutting-edge sensors, AI-driven systems, and advanced algorithms for real-world autonomous navigation.</p>
            <p>Our work aims to push the boundaries of autonomous vehicle research, leveraging deep learning, robotics, and state-of-the-art machine learning techniques to solve complex problems in the field.</p>
            <p><span style="color: #d4af37;">GitHub:</span> <a href="https://github.com/Nova-UTD/navigator.git" target="_blank">https://github.com/Nova-UTD/navigator.git</a></p>
        </section>

        <section>
            <h3 style="color: #d4af37;">Brake Light Detection</h3>            <p>One of my key contributions to the NOVA program is the development of a brake light detection system. This system utilizes YOLOv8, a state-of-the-art object detection model, to identify and classify braking behaviors of vehicles in real-time. By integrating this with ROS2, we aim to enhance the decision-making capabilities of our autonomous vehicle prototype.</p>
            <div class="brake-light-images">
                <img src="assets\images\brake1.png" alt="Annotated Brake Light Detection - Example 1" style="max-width: 45%; margin: 10px;">
                <img src="assets\images\brake2.png" alt="Annotated Brake Light Detection - Example 2" style="max-width: 45%; margin: 10px;">
                <p class="citation">
                    <em>Base images and dataset courtesy of IM Lab, Kookmin University via Roboflow Universe, licensed under 
                    <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC BY 4.0</a>. Annotations created using YOLOv8 by Sai Peram.</em><br>
                    <strong>Dataset link:</strong> 
                    <a href="https://universe.roboflow.com/imlab-kookmin-univ/brake-light-detection" target="_blank">
                        Brake-Light-Detection Dataset
                    </a>
                </p>
            </div>
        </section>
    </main>

    <footer>
        <p>&copy; 2025 Sai Peram</p>
    </footer>
</body>
</html>
